{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bynary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    balanced_accuracy_score, precision_recall_curve, auc\n",
    ")\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from scipy.stats import wilcoxon, shapiro, ttest_rel\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.w2v_feature_extraction import W2VTransformer\n",
    "from utils.text_preprocessing import preprocess_text, TextPreprocessor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"../dataset/training_set.csv\")  \n",
    "df_train = df_train[['text', 'binary_label']]\n",
    "df_train = df_train[\n",
    "    df_train['text'].notna() & df_train['text'].str.strip().astype(bool)\n",
    "]\n",
    "model1 = Word2Vec.load(\"../model/word2vec_model1.model\")\n",
    "\n",
    "X_text = df_train[\"text\"].fillna(\"\").astype(str)\n",
    "y_binary = df_train[\"binary_label\"].map({\n",
    "    \"cyberbullying\": 1,\n",
    "    \"not_cyberbullying\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NestedLoop CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nested CV — BoW + LogisticRegression\n",
      "  Fold 1: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 2: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 3: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 4: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 5: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 6: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 7: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 8: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 9: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 10: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "Chosen params (mode over 10 folds): {'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "\n",
      "Nested CV — BoW + RandomForest\n",
      "  Fold 1: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 2: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 3: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 4: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 100, 'model__random_state': 42}\n",
      "  Fold 5: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 6: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 7: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 100, 'model__random_state': 42}\n",
      "  Fold 8: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 9: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 10: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "Chosen params (mode over 10 folds): {'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "\n",
      "Nested CV — BoW + LinearSVM\n",
      "  Fold 1: best_params={'model__C': 0.01}\n",
      "  Fold 2: best_params={'model__C': 0.01}\n",
      "  Fold 3: best_params={'model__C': 1}\n",
      "  Fold 4: best_params={'model__C': 1}\n",
      "  Fold 5: best_params={'model__C': 0.01}\n",
      "  Fold 6: best_params={'model__C': 0.01}\n",
      "  Fold 7: best_params={'model__C': 0.01}\n",
      "  Fold 8: best_params={'model__C': 1}\n",
      "  Fold 9: best_params={'model__C': 1}\n",
      "  Fold 10: best_params={'model__C': 0.01}\n",
      "Chosen params (mode over 10 folds): {'model__C': 0.01}\n",
      "\n",
      "Nested CV — TF-IDF + LogisticRegression\n",
      "  Fold 1: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 2: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 3: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 4: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 5: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 6: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 7: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 8: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 9: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "  Fold 10: best_params={'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "Chosen params (mode over 10 folds): {'model__C': 1, 'model__class_weight': 'balanced'}\n",
      "\n",
      "Nested CV — TF-IDF + RandomForest\n",
      "  Fold 1: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 2: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 3: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 4: best_params={'model__class_weight': 'balanced', 'model__max_depth': None, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 5: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 6: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 7: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 8: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 9: best_params={'model__class_weight': 'balanced', 'model__max_depth': None, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 10: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "Chosen params (mode over 10 folds): {'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "\n",
      "Nested CV — TF-IDF + LinearSVM\n",
      "  Fold 1: best_params={'model__C': 10}\n",
      "  Fold 2: best_params={'model__C': 1}\n",
      "  Fold 3: best_params={'model__C': 10}\n",
      "  Fold 4: best_params={'model__C': 1}\n",
      "  Fold 5: best_params={'model__C': 1}\n",
      "  Fold 6: best_params={'model__C': 1}\n",
      "  Fold 7: best_params={'model__C': 1}\n",
      "  Fold 8: best_params={'model__C': 10}\n",
      "  Fold 9: best_params={'model__C': 1}\n",
      "  Fold 10: best_params={'model__C': 1}\n",
      "Chosen params (mode over 10 folds): {'model__C': 1}\n",
      "\n",
      "Nested CV — W2V-1 + LogisticRegression\n",
      "  Fold 1: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 2: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 3: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 4: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 5: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 6: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 7: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 8: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 9: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "  Fold 10: best_params={'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "Chosen params (mode over 10 folds): {'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "\n",
      "Nested CV — W2V-1 + RandomForest\n",
      "  Fold 1: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 2: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 100, 'model__random_state': 42}\n",
      "  Fold 3: best_params={'model__class_weight': 'balanced', 'model__max_depth': None, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 4: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 5: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 6: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 7: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 8: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "  Fold 9: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 1000, 'model__random_state': 42}\n",
      "  Fold 10: best_params={'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "Chosen params (mode over 10 folds): {'model__class_weight': 'balanced', 'model__max_depth': 20, 'model__n_estimators': 500, 'model__random_state': 42}\n",
      "\n",
      "Nested CV — W2V-1 + LinearSVM\n",
      "  Fold 1: best_params={'model__C': 0.01}\n",
      "  Fold 2: best_params={'model__C': 0.01}\n",
      "  Fold 3: best_params={'model__C': 0.01}\n",
      "  Fold 4: best_params={'model__C': 1}\n",
      "  Fold 5: best_params={'model__C': 0.01}\n",
      "  Fold 6: best_params={'model__C': 0.01}\n",
      "  Fold 7: best_params={'model__C': 0.01}\n",
      "  Fold 8: best_params={'model__C': 0.01}\n",
      "  Fold 9: best_params={'model__C': 0.01}\n",
      "  Fold 10: best_params={'model__C': 0.01}\n",
      "Chosen params (mode over 10 folds): {'model__C': 0.01}\n",
      "=== Nested CV ===\n",
      "  Vectorizer          Classifier  Mean f1_macro  Mean accuracy  \\\n",
      "0     TF-IDF  LogisticRegression       0.726069       0.804865   \n",
      "1        BoW  LogisticRegression       0.725971       0.813960   \n",
      "2     TF-IDF           LinearSVM       0.723712       0.800409   \n",
      "3        BoW           LinearSVM       0.723284       0.808796   \n",
      "4        BoW        RandomForest       0.717003       0.782376   \n",
      "5     TF-IDF        RandomForest       0.716418       0.788064   \n",
      "6      W2V-1  LogisticRegression       0.688008       0.771394   \n",
      "7      W2V-1           LinearSVM       0.685688       0.767620   \n",
      "8      W2V-1        RandomForest       0.677147       0.810945   \n",
      "\n",
      "   Mean precision  Mean recall   Mean f1  Std f1_macro  Std accuracy  \\\n",
      "0        0.954029     0.804667  0.872959      0.006945      0.007003   \n",
      "1        0.941532     0.828254  0.881224      0.006746      0.005840   \n",
      "2        0.956956     0.796364  0.869248      0.007846      0.008319   \n",
      "3        0.944441     0.818757  0.877098      0.006590      0.005756   \n",
      "4        0.975631     0.757807  0.853000      0.007483      0.007750   \n",
      "5        0.968466     0.772275  0.858258      0.008257      0.011832   \n",
      "6        0.942390     0.772966  0.849284      0.005488      0.005804   \n",
      "7        0.943780     0.766865  0.846139      0.006355      0.006880   \n",
      "8        0.897570     0.872755  0.884980      0.007977      0.005702   \n",
      "\n",
      "   Std precision  Std recall    Std f1  \n",
      "0       0.004034    0.009846  0.005238  \n",
      "1       0.004872    0.008769  0.004247  \n",
      "2       0.003659    0.011461  0.006295  \n",
      "3       0.003389    0.007120  0.004099  \n",
      "4       0.002173    0.009383  0.005980  \n",
      "5       0.023774    0.036043  0.011849  \n",
      "6       0.003036    0.007766  0.004479  \n",
      "7       0.002972    0.008999  0.005342  \n",
      "8       0.002755    0.005850  0.003708  \n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../model/binary\", exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "combinations = [\n",
    "    (\"BoW\",   CountVectorizer(min_df=0.005)),\n",
    "    (\"TF-IDF\", TfidfVectorizer(min_df=0.005)),\n",
    "    (\"W2V-1\", W2VTransformer(model1))\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model__C\": [0.01, 0.1, 1],\n",
    "        \"model__class_weight\": [\"balanced\"]\n",
    "    },\n",
    "    \"LinearSVM\": {\n",
    "        \"model__C\": [0.01, 1, 10]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model__n_estimators\": [100, 500, 1000],\n",
    "        \"model__max_depth\": [None, 20],\n",
    "        \"model__class_weight\": [\"balanced\"],\n",
    "        \"model__random_state\": [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000), param_grid[\"LogisticRegression\"]),\n",
    "    (\"RandomForest\", RandomForestClassifier(), param_grid[\"RandomForest\"]),\n",
    "    (\"LinearSVM\", LinearSVC(max_iter=2000), param_grid[\"LinearSVM\"])\n",
    "]\n",
    "\n",
    "scoring = [\"f1_macro\", \"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "nested_results = []\n",
    "\n",
    "for vec_name, vectorizer in combinations:\n",
    "    for clf_name, clf, grid_params in classifiers:\n",
    "        print(f\"\\nNested CV — {vec_name} + {clf_name}\")\n",
    "        \n",
    "        best_params_list = []\n",
    "        all_fold_metrics = {m: [] for m in scoring}\n",
    "        \n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X_text, y_binary), 1):\n",
    "            X_tr, X_te = X_text[train_idx], X_text[test_idx]\n",
    "            y_tr, y_te = y_binary[train_idx], y_binary[test_idx]\n",
    "            \n",
    "            pipe = Pipeline([\n",
    "                (\"preprocessing\", TextPreprocessor()),             \n",
    "                (\"vectorizer\", vectorizer),     \n",
    "                (\"smote\", SMOTE(random_state=42)),           \n",
    "                (\"model\", clf)\n",
    "            ])\n",
    "            \n",
    "            grid = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=grid_params,\n",
    "                scoring=scoring,\n",
    "                refit=\"f1_macro\",\n",
    "                cv=inner_cv,\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            grid.fit(X_tr, y_tr)\n",
    "            \n",
    "            best_params_list.append(grid.best_params_)\n",
    "            \n",
    "            y_pred = grid.predict(X_te)\n",
    "            scores = {\n",
    "                \"accuracy\":  np.mean(y_pred == y_te),\n",
    "                \"precision\": precision_score(y_te, y_pred, zero_division=0),\n",
    "                \"recall\":    recall_score(y_te, y_pred, zero_division=0),\n",
    "                \"f1\":        f1_score(y_te, y_pred, zero_division=0),\n",
    "                \"f1_macro\":  f1_score(y_te, y_pred, average=\"macro\", zero_division=0)\n",
    "            }\n",
    "            for m, val in scores.items():\n",
    "                all_fold_metrics[m].append(val)\n",
    "            \n",
    "            print(f\"  Fold {fold}: best_params={grid.best_params_}\")\n",
    "        \n",
    "        tuples = [tuple(sorted(d.items())) for d in best_params_list]\n",
    "        most_common_tuple, count = Counter(tuples).most_common(1)[0]\n",
    "        final_params = dict(most_common_tuple)\n",
    "        print(f\"Chosen params (mode over 10 folds): {final_params}\")\n",
    "        \n",
    "        summary = {\n",
    "            \"Vectorizer\": vec_name,\n",
    "            \"Classifier\": clf_name,\n",
    "            **{f\"Mean {m}\": np.mean(vals) for m, vals in all_fold_metrics.items()},\n",
    "            **{f\"Std {m}\":   np.std(vals)  for m, vals in all_fold_metrics.items()}\n",
    "        }\n",
    "        nested_results.append(summary)\n",
    "        \n",
    "        final_pipe = Pipeline([\n",
    "            (\"preprocessing\", TextPreprocessor()),\n",
    "            (\"vectorizer\",    vectorizer),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\"model\",         clf)\n",
    "        ])\n",
    "        final_pipe.set_params(**final_params)\n",
    "        final_pipe.fit(X_text, y_binary)\n",
    "        \n",
    "        filename = f\"../model/binary/{clf_name}_{vec_name}.pkl\"\n",
    "        joblib.dump(final_pipe, filename)\n",
    "\n",
    "nested_df = pd.DataFrame(nested_results)\\\n",
    "              .sort_values(by=\"Mean f1_macro\", ascending=False)\\\n",
    "              .reset_index(drop=True)\n",
    "\n",
    "print(\"=== Nested CV ===\")\n",
    "print(nested_df)\n",
    "nested_df.to_csv(\"../model/binary/nested_cv_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression + TF-IDF\n",
      "Evaluating LogisticRegression + BoW\n",
      "Evaluating LinearSVM + TF-IDF\n",
      "Evaluating LinearSVM + BoW\n",
      "Evaluating RandomForest + BoW\n",
      "Evaluating RandomForest + TF-IDF\n",
      "Evaluating LogisticRegression + W2V-1\n",
      "Evaluating LinearSVM + W2V-1\n",
      "Evaluating RandomForest + W2V-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression + TF-IDF</th>\n",
       "      <th>LogisticRegression + BoW</th>\n",
       "      <th>LinearSVM + TF-IDF</th>\n",
       "      <th>LinearSVM + BoW</th>\n",
       "      <th>RandomForest + BoW</th>\n",
       "      <th>RandomForest + TF-IDF</th>\n",
       "      <th>LogisticRegression + W2V-1</th>\n",
       "      <th>LinearSVM + W2V-1</th>\n",
       "      <th>RandomForest + W2V-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.726522</td>\n",
       "      <td>0.726851</td>\n",
       "      <td>0.724317</td>\n",
       "      <td>0.724573</td>\n",
       "      <td>0.717240</td>\n",
       "      <td>0.717996</td>\n",
       "      <td>0.688628</td>\n",
       "      <td>0.687189</td>\n",
       "      <td>0.677758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>0.006442</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.009034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.711210</td>\n",
       "      <td>0.715139</td>\n",
       "      <td>0.712287</td>\n",
       "      <td>0.712928</td>\n",
       "      <td>0.705602</td>\n",
       "      <td>0.704842</td>\n",
       "      <td>0.677691</td>\n",
       "      <td>0.674831</td>\n",
       "      <td>0.661060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.720880</td>\n",
       "      <td>0.723111</td>\n",
       "      <td>0.719312</td>\n",
       "      <td>0.720278</td>\n",
       "      <td>0.714003</td>\n",
       "      <td>0.713512</td>\n",
       "      <td>0.685661</td>\n",
       "      <td>0.684403</td>\n",
       "      <td>0.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.725932</td>\n",
       "      <td>0.726585</td>\n",
       "      <td>0.723065</td>\n",
       "      <td>0.724603</td>\n",
       "      <td>0.716005</td>\n",
       "      <td>0.718727</td>\n",
       "      <td>0.688122</td>\n",
       "      <td>0.686862</td>\n",
       "      <td>0.676608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.732573</td>\n",
       "      <td>0.730588</td>\n",
       "      <td>0.728957</td>\n",
       "      <td>0.728759</td>\n",
       "      <td>0.722428</td>\n",
       "      <td>0.722943</td>\n",
       "      <td>0.691687</td>\n",
       "      <td>0.691730</td>\n",
       "      <td>0.685341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.742601</td>\n",
       "      <td>0.744287</td>\n",
       "      <td>0.739792</td>\n",
       "      <td>0.741388</td>\n",
       "      <td>0.728861</td>\n",
       "      <td>0.728552</td>\n",
       "      <td>0.698507</td>\n",
       "      <td>0.696917</td>\n",
       "      <td>0.695181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LogisticRegression + TF-IDF  LogisticRegression + BoW  \\\n",
       "count                    30.000000                 30.000000   \n",
       "mean                      0.726522                  0.726851   \n",
       "std                       0.007008                  0.006301   \n",
       "min                       0.711210                  0.715139   \n",
       "25%                       0.720880                  0.723111   \n",
       "50%                       0.725932                  0.726585   \n",
       "75%                       0.732573                  0.730588   \n",
       "max                       0.742601                  0.744287   \n",
       "\n",
       "       LinearSVM + TF-IDF  LinearSVM + BoW  RandomForest + BoW  \\\n",
       "count           30.000000        30.000000           30.000000   \n",
       "mean             0.724317         0.724573            0.717240   \n",
       "std              0.006906         0.006442            0.006390   \n",
       "min              0.712287         0.712928            0.705602   \n",
       "25%              0.719312         0.720278            0.714003   \n",
       "50%              0.723065         0.724603            0.716005   \n",
       "75%              0.728957         0.728759            0.722428   \n",
       "max              0.739792         0.741388            0.728861   \n",
       "\n",
       "       RandomForest + TF-IDF  LogisticRegression + W2V-1  LinearSVM + W2V-1  \\\n",
       "count              30.000000                   30.000000          30.000000   \n",
       "mean                0.717996                    0.688628           0.687189   \n",
       "std                 0.007153                    0.005012           0.005405   \n",
       "min                 0.704842                    0.677691           0.674831   \n",
       "25%                 0.713512                    0.685661           0.684403   \n",
       "50%                 0.718727                    0.688122           0.686862   \n",
       "75%                 0.722943                    0.691687           0.691730   \n",
       "max                 0.728552                    0.698507           0.696917   \n",
       "\n",
       "       RandomForest + W2V-1  \n",
       "count             30.000000  \n",
       "mean               0.677758  \n",
       "std                0.009034  \n",
       "min                0.661060  \n",
       "25%                0.670300  \n",
       "50%                0.676608  \n",
       "75%                0.685341  \n",
       "max                0.695181  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "y = y_binary\n",
    "\n",
    "results = pd.read_csv(\"../model/binary/nested_cv_results.csv\")\n",
    "\n",
    "results_sorted = results.head(9)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "scorer_f1macro = make_scorer(f1_score, average=\"macro\")\n",
    "\n",
    "scores_dict = {}\n",
    "\n",
    "for _, row in results_sorted.iterrows():\n",
    "    vec_name = row[\"Vectorizer\"]\n",
    "    clf_name = row[\"Classifier\"]\n",
    "\n",
    "    print(f\"Evaluating {clf_name} + {vec_name}\")\n",
    "\n",
    "    model_path = f\"../model/binary/{clf_name}_{vec_name}.pkl\"\n",
    "    pipeline = joblib.load(model_path)\n",
    "\n",
    "    accuracy_scores = cross_val_score(\n",
    "        pipeline, X_text, y, cv=cv, scoring=scorer_f1macro, n_jobs=-1\n",
    "    )\n",
    "    key = f\"{clf_name} + {vec_name}\"\n",
    "    scores_dict[key] = accuracy_scores\n",
    "\n",
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df.to_csv(\"../model/binary/repeated_cv_scores.csv\", index=False)\n",
    "\n",
    "display(scores_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise victory matrix (1 = win, 0 = no win, -1 = defeat):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression + TF-IDF</th>\n",
       "      <th>LogisticRegression + BoW</th>\n",
       "      <th>LinearSVM + TF-IDF</th>\n",
       "      <th>LinearSVM + BoW</th>\n",
       "      <th>RandomForest + BoW</th>\n",
       "      <th>RandomForest + TF-IDF</th>\n",
       "      <th>LogisticRegression + W2V-1</th>\n",
       "      <th>LinearSVM + W2V-1</th>\n",
       "      <th>RandomForest + W2V-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + TF-IDF</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + BoW</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM + TF-IDF</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM + BoW</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest + BoW</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest + TF-IDF</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression + W2V-1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM + W2V-1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest + W2V-1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             LogisticRegression + TF-IDF  \\\n",
       "LogisticRegression + TF-IDF                            0   \n",
       "LogisticRegression + BoW                               0   \n",
       "LinearSVM + TF-IDF                                    -1   \n",
       "LinearSVM + BoW                                       -1   \n",
       "RandomForest + BoW                                    -1   \n",
       "RandomForest + TF-IDF                                 -1   \n",
       "LogisticRegression + W2V-1                            -1   \n",
       "LinearSVM + W2V-1                                     -1   \n",
       "RandomForest + W2V-1                                  -1   \n",
       "\n",
       "                             LogisticRegression + BoW  LinearSVM + TF-IDF  \\\n",
       "LogisticRegression + TF-IDF                         0                   1   \n",
       "LogisticRegression + BoW                            0                   1   \n",
       "LinearSVM + TF-IDF                                 -1                   0   \n",
       "LinearSVM + BoW                                    -1                   0   \n",
       "RandomForest + BoW                                 -1                  -1   \n",
       "RandomForest + TF-IDF                              -1                  -1   \n",
       "LogisticRegression + W2V-1                         -1                  -1   \n",
       "LinearSVM + W2V-1                                  -1                  -1   \n",
       "RandomForest + W2V-1                               -1                  -1   \n",
       "\n",
       "                             LinearSVM + BoW  RandomForest + BoW  \\\n",
       "LogisticRegression + TF-IDF                1                   1   \n",
       "LogisticRegression + BoW                   1                   1   \n",
       "LinearSVM + TF-IDF                         0                   1   \n",
       "LinearSVM + BoW                            0                   1   \n",
       "RandomForest + BoW                        -1                   0   \n",
       "RandomForest + TF-IDF                     -1                   0   \n",
       "LogisticRegression + W2V-1                -1                  -1   \n",
       "LinearSVM + W2V-1                         -1                  -1   \n",
       "RandomForest + W2V-1                      -1                  -1   \n",
       "\n",
       "                             RandomForest + TF-IDF  \\\n",
       "LogisticRegression + TF-IDF                      1   \n",
       "LogisticRegression + BoW                         1   \n",
       "LinearSVM + TF-IDF                               1   \n",
       "LinearSVM + BoW                                  1   \n",
       "RandomForest + BoW                               0   \n",
       "RandomForest + TF-IDF                            0   \n",
       "LogisticRegression + W2V-1                      -1   \n",
       "LinearSVM + W2V-1                               -1   \n",
       "RandomForest + W2V-1                            -1   \n",
       "\n",
       "                             LogisticRegression + W2V-1  LinearSVM + W2V-1  \\\n",
       "LogisticRegression + TF-IDF                           1                  1   \n",
       "LogisticRegression + BoW                              1                  1   \n",
       "LinearSVM + TF-IDF                                    1                  1   \n",
       "LinearSVM + BoW                                       1                  1   \n",
       "RandomForest + BoW                                    1                  1   \n",
       "RandomForest + TF-IDF                                 1                  1   \n",
       "LogisticRegression + W2V-1                            0                  1   \n",
       "LinearSVM + W2V-1                                    -1                  0   \n",
       "RandomForest + W2V-1                                 -1                 -1   \n",
       "\n",
       "                             RandomForest + W2V-1  \n",
       "LogisticRegression + TF-IDF                     1  \n",
       "LogisticRegression + BoW                        1  \n",
       "LinearSVM + TF-IDF                              1  \n",
       "LinearSVM + BoW                                 1  \n",
       "RandomForest + BoW                              1  \n",
       "RandomForest + TF-IDF                           1  \n",
       "LogisticRegression + W2V-1                      1  \n",
       "LinearSVM + W2V-1                               1  \n",
       "RandomForest + W2V-1                            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of victories per model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression + TF-IDF    7\n",
       "LogisticRegression + BoW       7\n",
       "LinearSVM + TF-IDF             3\n",
       "LinearSVM + BoW                3\n",
       "RandomForest + BoW            -1\n",
       "RandomForest + TF-IDF         -1\n",
       "LogisticRegression + W2V-1    -4\n",
       "LinearSVM + W2V-1             -6\n",
       "RandomForest + W2V-1          -8\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner(s) with 7 victories: LogisticRegression + TF-IDF, LogisticRegression + BoW\n",
      "\n",
      "Head-to-head details for LogisticRegression + TF-IDF:\n",
      "LogisticRegression + TF-IDF vs LogisticRegression + BoW: t-test, stat=-0.4003, p=0.6918 -> no win\n",
      "LogisticRegression + TF-IDF vs LinearSVM + TF-IDF: t-test, stat=3.8696, p=0.0006 -> win\n",
      "LogisticRegression + TF-IDF vs LinearSVM + BoW: t-test, stat=2.2984, p=0.0289 -> win\n",
      "LogisticRegression + TF-IDF vs RandomForest + BoW: t-test, stat=10.0545, p=0.0000 -> win\n",
      "LogisticRegression + TF-IDF vs RandomForest + TF-IDF: t-test, stat=8.7312, p=0.0000 -> win\n",
      "LogisticRegression + TF-IDF vs LogisticRegression + W2V-1: t-test, stat=30.8589, p=0.0000 -> win\n",
      "LogisticRegression + TF-IDF vs LinearSVM + W2V-1: t-test, stat=30.7596, p=0.0000 -> win\n",
      "LogisticRegression + TF-IDF vs RandomForest + W2V-1: t-test, stat=27.8691, p=0.0000 -> win\n",
      "\n",
      "Head-to-head details for LogisticRegression + BoW:\n",
      "LogisticRegression + BoW vs LogisticRegression + TF-IDF: t-test, stat=0.4003, p=0.6918 -> no win\n",
      "LogisticRegression + BoW vs LinearSVM + TF-IDF: t-test, stat=2.9451, p=0.0063 -> win\n",
      "LogisticRegression + BoW vs LinearSVM + BoW: t-test, stat=7.6112, p=0.0000 -> win\n",
      "LogisticRegression + BoW vs RandomForest + BoW: t-test, stat=10.1741, p=0.0000 -> win\n",
      "LogisticRegression + BoW vs RandomForest + TF-IDF: Wilcoxon, stat=20.0000, p=0.0000 -> win\n",
      "LogisticRegression + BoW vs LogisticRegression + W2V-1: t-test, stat=28.9065, p=0.0000 -> win\n",
      "LogisticRegression + BoW vs LinearSVM + W2V-1: t-test, stat=29.9886, p=0.0000 -> win\n",
      "LogisticRegression + BoW vs RandomForest + W2V-1: t-test, stat=26.0417, p=0.0000 -> win\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"../model/binary/repeated_cv_scores.csv\")\n",
    "results = pd.DataFrame(results)\\\n",
    "              .sort_values(by=\"Mean f1_macro\", ascending=False)\\\n",
    "              .reset_index(drop=True)\n",
    "\n",
    "model_names = list(scores_df.columns)\n",
    "N = len(model_names)\n",
    "matrix = pd.DataFrame(0, index=model_names, columns=model_names)\n",
    "\n",
    "for i in range(N):\n",
    "    name_i = model_names[i]\n",
    "    for j in range(i+1, N):\n",
    "        name_j = model_names[j]\n",
    "        diffs = scores_df[name_i] - scores_df[name_j]\n",
    "        stat_norm, p_norm = shapiro(diffs)\n",
    "        if p_norm > 0.05:\n",
    "            stat_test, p_test = ttest_rel(\n",
    "                scores_df[name_i], scores_df[name_j]\n",
    "            )\n",
    "        else:\n",
    "            stat_test, p_test = wilcoxon(\n",
    "                scores_df[name_i], scores_df[name_j]\n",
    "            )\n",
    "        if p_test < 0.05 :\n",
    "            if scores_df[name_i].mean() > scores_df[name_j].mean():\n",
    "                matrix.loc[name_i, name_j] = 1\n",
    "                matrix.loc[name_j, name_i] = -1\n",
    "            elif scores_df[name_i].mean() < scores_df[name_j].mean():\n",
    "                matrix.loc[name_i, name_j] = -1\n",
    "                matrix.loc[name_j, name_i] = 1\n",
    "\n",
    "print(\"\\nPairwise victory matrix (1 = win, 0 = no win, -1 = defeat):\")\n",
    "display(matrix)\n",
    "\n",
    "wins = matrix.sum(axis=1)\n",
    "print(\"\\nNumber of victories per model:\")\n",
    "display(wins)\n",
    "\n",
    "max_wins = wins.max()\n",
    "winners = wins[wins == max_wins].index.tolist()\n",
    "print(f\"\\nWinner(s) with {max_wins} victories: {', '.join(winners)}\")\n",
    "\n",
    "for winner in winners:\n",
    "    print(f\"\\nHead-to-head details for {winner}:\")\n",
    "    for opponent in model_names:\n",
    "        if opponent == winner:\n",
    "            continue\n",
    "        diffs = scores_df[winner] - scores_df[opponent]\n",
    "        stat_norm, p_norm = shapiro(diffs)\n",
    "        if p_norm > 0.05:\n",
    "            stat_test, p_test = ttest_rel(\n",
    "                scores_df[winner], scores_df[opponent]\n",
    "            )\n",
    "            test_name = 't-test'\n",
    "        else:\n",
    "            stat_test, p_test = wilcoxon(\n",
    "                scores_df[winner], scores_df[opponent]\n",
    "            )\n",
    "            test_name = 'Wilcoxon'\n",
    "        result = 'win' if matrix.loc[winner, opponent] == 1 else 'no win'\n",
    "        print(\n",
    "            f\"{winner} vs {opponent}: {test_name}, \"\n",
    "            f\"stat={stat_test:.4f}, p={p_test:.4f} -> {result}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of two best performing model on secondary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression + TF-IDF\n",
      "Evaluating LogisticRegression + BoW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression + TF-IDF - accuracy</th>\n",
       "      <th>LogisticRegression + TF-IDF - precision</th>\n",
       "      <th>LogisticRegression + TF-IDF - recall</th>\n",
       "      <th>LogisticRegression + TF-IDF - f1</th>\n",
       "      <th>LogisticRegression + BoW - accuracy</th>\n",
       "      <th>LogisticRegression + BoW - precision</th>\n",
       "      <th>LogisticRegression + BoW - recall</th>\n",
       "      <th>LogisticRegression + BoW - f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.805240</td>\n",
       "      <td>0.954169</td>\n",
       "      <td>0.804992</td>\n",
       "      <td>0.873231</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.943205</td>\n",
       "      <td>0.825979</td>\n",
       "      <td>0.880688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.003839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.948576</td>\n",
       "      <td>0.789623</td>\n",
       "      <td>0.864384</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>0.936610</td>\n",
       "      <td>0.813522</td>\n",
       "      <td>0.875525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.801743</td>\n",
       "      <td>0.950999</td>\n",
       "      <td>0.800409</td>\n",
       "      <td>0.871023</td>\n",
       "      <td>0.809187</td>\n",
       "      <td>0.941614</td>\n",
       "      <td>0.822271</td>\n",
       "      <td>0.877563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.805137</td>\n",
       "      <td>0.953424</td>\n",
       "      <td>0.804529</td>\n",
       "      <td>0.873084</td>\n",
       "      <td>0.813786</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.825943</td>\n",
       "      <td>0.880658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.808073</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.807738</td>\n",
       "      <td>0.874888</td>\n",
       "      <td>0.816198</td>\n",
       "      <td>0.945031</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.882606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.820446</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.824843</td>\n",
       "      <td>0.884154</td>\n",
       "      <td>0.827785</td>\n",
       "      <td>0.950404</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.890409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LogisticRegression + TF-IDF - accuracy  \\\n",
       "count                               30.000000   \n",
       "mean                                 0.805240   \n",
       "std                                  0.006215   \n",
       "min                                  0.792453   \n",
       "25%                                  0.801743   \n",
       "50%                                  0.805137   \n",
       "75%                                  0.808073   \n",
       "max                                  0.820446   \n",
       "\n",
       "       LogisticRegression + TF-IDF - precision  \\\n",
       "count                                30.000000   \n",
       "mean                                  0.954169   \n",
       "std                                   0.003737   \n",
       "min                                   0.948576   \n",
       "25%                                   0.950999   \n",
       "50%                                   0.953424   \n",
       "75%                                   0.956748   \n",
       "max                                   0.962164   \n",
       "\n",
       "       LogisticRegression + TF-IDF - recall  LogisticRegression + TF-IDF - f1  \\\n",
       "count                             30.000000                         30.000000   \n",
       "mean                               0.804992                          0.873231   \n",
       "std                                0.007553                          0.004479   \n",
       "min                                0.789623                          0.864384   \n",
       "25%                                0.800409                          0.871023   \n",
       "50%                                0.804529                          0.873084   \n",
       "75%                                0.807738                          0.874888   \n",
       "max                                0.824843                          0.884154   \n",
       "\n",
       "       LogisticRegression + BoW - accuracy  \\\n",
       "count                            30.000000   \n",
       "mean                              0.813505   \n",
       "std                               0.005415   \n",
       "min                               0.805767   \n",
       "25%                               0.809187   \n",
       "50%                               0.813786   \n",
       "75%                               0.816198   \n",
       "max                               0.827785   \n",
       "\n",
       "       LogisticRegression + BoW - precision  \\\n",
       "count                             30.000000   \n",
       "mean                               0.943205   \n",
       "std                                0.003329   \n",
       "min                                0.936610   \n",
       "25%                                0.941614   \n",
       "50%                                0.943038   \n",
       "75%                                0.945031   \n",
       "max                                0.950404   \n",
       "\n",
       "       LogisticRegression + BoW - recall  LogisticRegression + BoW - f1  \n",
       "count                          30.000000                      30.000000  \n",
       "mean                            0.825979                       0.880688  \n",
       "std                             0.006881                       0.003839  \n",
       "min                             0.813522                       0.875525  \n",
       "25%                             0.822271                       0.877563  \n",
       "50%                             0.825943                       0.880658  \n",
       "75%                             0.829034                       0.882606  \n",
       "max                             0.843396                       0.890409  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "y = y_binary\n",
    "\n",
    "results = pd.read_csv(\"../model/binary/nested_cv_results.csv\")\n",
    "\n",
    "results_sorted = results.head(2)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "scores_dict = {}\n",
    "\n",
    "for _, row in results_sorted.iterrows():\n",
    "    vec_name = row[\"Vectorizer\"]\n",
    "    clf_name = row[\"Classifier\"]\n",
    "    \n",
    "    print(f\"Evaluating {clf_name} + {vec_name}\")\n",
    "    \n",
    "    model_path = f\"../model/binary/{clf_name}_{vec_name}.pkl\"\n",
    "    pipeline = joblib.load(model_path)\n",
    "\n",
    "    results_cv = cross_validate(\n",
    "        pipeline, X_text, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False\n",
    "    )\n",
    "    \n",
    "    key = f\"{clf_name} + {vec_name}\"\n",
    "    for metric in scoring:\n",
    "        scores_dict[f\"{key} - {metric}\"] = results_cv[f\"test_{metric}\"]\n",
    "\n",
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df.to_csv(\"../model/binary/repeated_cv_scores_second_comparison.csv\", index=False)\n",
    "\n",
    "display(scores_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model per metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>LogisticRegression + BoW</th>\n",
       "      <th>LogisticRegression + TF-IDF</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Test Used</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.813505</td>\n",
       "      <td>0.805240</td>\n",
       "      <td>9.133021e-14</td>\n",
       "      <td>t-test</td>\n",
       "      <td>LogisticRegression + BoW Wins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.880688</td>\n",
       "      <td>0.873231</td>\n",
       "      <td>1.046418e-16</td>\n",
       "      <td>t-test</td>\n",
       "      <td>LogisticRegression + BoW Wins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.943205</td>\n",
       "      <td>0.954169</td>\n",
       "      <td>3.311315e-20</td>\n",
       "      <td>t-test</td>\n",
       "      <td>LogisticRegression + TF-IDF Wins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.825979</td>\n",
       "      <td>0.804992</td>\n",
       "      <td>4.431484e-24</td>\n",
       "      <td>t-test</td>\n",
       "      <td>LogisticRegression + BoW Wins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  LogisticRegression + BoW  LogisticRegression + TF-IDF  \\\n",
       "0   accuracy                  0.813505                     0.805240   \n",
       "1         f1                  0.880688                     0.873231   \n",
       "2  precision                  0.943205                     0.954169   \n",
       "3     recall                  0.825979                     0.804992   \n",
       "\n",
       "        p-value Test Used                            Result  \n",
       "0  9.133021e-14    t-test     LogisticRegression + BoW Wins  \n",
       "1  1.046418e-16    t-test     LogisticRegression + BoW Wins  \n",
       "2  3.311315e-20    t-test  LogisticRegression + TF-IDF Wins  \n",
       "3  4.431484e-24    t-test     LogisticRegression + BoW Wins  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1 Wins</th>\n",
       "      <th>Model 2 Wins</th>\n",
       "      <th>Ties</th>\n",
       "      <th>LogisticRegression + BoW</th>\n",
       "      <th>LogisticRegression + TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model 1 Wins  Model 2 Wins  Ties  LogisticRegression + BoW  \\\n",
       "0             0             0     0                         3   \n",
       "\n",
       "   LogisticRegression + TF-IDF  \n",
       "0                            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "\n",
    "df = pd.read_csv(\"../model/binary/repeated_cv_scores_second_comparison.csv\")\n",
    "\n",
    "model_names = list(set(col.split(\" - \")[0] for col in df.columns))\n",
    "metrics = list(set(col.split(\" - \")[1] for col in df.columns))\n",
    "\n",
    "model_names.sort()\n",
    "metrics.sort()\n",
    "\n",
    "results_summary = []\n",
    "comparison_summary = {\"Model 1 Wins\": 0, \"Model 2 Wins\": 0, \"Ties\": 0}\n",
    "\n",
    "for metric in metrics:\n",
    "    col1 = f\"{model_names[0]} - {metric}\"\n",
    "    col2 = f\"{model_names[1]} - {metric}\"\n",
    "    \n",
    "    diff = df[col1] - df[col2]\n",
    "    \n",
    "    stat, p_normality = shapiro(diff)\n",
    "    if p_normality > 0.05:\n",
    "        test_stat, p_value = ttest_rel(df[col1], df[col2])\n",
    "    else:\n",
    "        test_stat, p_value = wilcoxon(df[col1], df[col2])\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        result = \"Tie\"\n",
    "        comparison_summary[\"Ties\"] += 1\n",
    "    else:\n",
    "        if diff.mean() > 0:\n",
    "            result = f\"{model_names[0]} Wins\"\n",
    "            comparison_summary[f\"{model_names[0]}\"] = comparison_summary.get(f\"{model_names[0]}\", 0) + 1\n",
    "        else:\n",
    "            result = f\"{model_names[1]} Wins\"\n",
    "            comparison_summary[f\"{model_names[1]}\"] = comparison_summary.get(f\"{model_names[1]}\", 0) + 1\n",
    "\n",
    "    results_summary.append({\n",
    "        \"Metric\": metric,\n",
    "        f\"{model_names[0]}\": df[col1].mean(),\n",
    "        f\"{model_names[1]}\": df[col2].mean(),\n",
    "        \"p-value\": p_value,\n",
    "        \"Test Used\": \"t-test\" if p_normality > 0.05 else \"Wilcoxon\",\n",
    "        \"Result\": result\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "\n",
    "comparison_df = pd.DataFrame([comparison_summary])\n",
    "\n",
    "print(\"Best model per metrics:\")\n",
    "display(results_df)\n",
    "\n",
    "print(\"Resuming:\")\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LogisticRegression + BoW ---\n",
      "Accuracy:             0.8112\n",
      "Balanced Accuracy:    0.7833\n",
      "Precision:            0.9410\n",
      "Recall (Sensitivity): 0.8252\n",
      "Specificity:          0.7413\n",
      "F1 Score:             0.8793\n",
      "F1 Score macro:       0.7230\n",
      "AUC-ROC:              0.8800\n",
      "PR-AUC:               0.9751\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set loading\n",
    "df_eval_sorted = pd.read_csv(\"../model/binary/nested_cv_results.csv\")\n",
    "df_eval_sorted = pd.DataFrame(df_eval_sorted)\\\n",
    "              .sort_values(by=\"Mean f1_macro\", ascending=False)\\\n",
    "              .reset_index(drop=True)\n",
    "df_test = pd.read_csv(\"../dataset/test_set.csv\")\n",
    "X_test_text = df_test[\"text\"]\n",
    "y_test = df_test[\"binary_label\"].map({\"cyberbullying\": 1, \"not_cyberbullying\": 0}).values\n",
    "\n",
    "# Evaluation Metrics\n",
    "def print_metrics_and_confmat(y_true, y_pred, y_proba, title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    spec = recall_score(y_true, y_pred, pos_label=0)\n",
    "    auc_roc = roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_proba)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "    print(f\"Accuracy:             {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy:    {bal_acc:.4f}\")\n",
    "    print(f\"Precision:            {prec:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {rec:.4f}\")\n",
    "    print(f\"Specificity:          {spec:.4f}\")\n",
    "    print(f\"F1 Score:             {f1:.4f}\")\n",
    "    print(f\"F1 Score macro:       {f1_macro:.4f}\")\n",
    "    print(f\"AUC-ROC:              {auc_roc:.4f}\")\n",
    "    print(f\"PR-AUC:               {pr_auc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Cyberbullying\", \"Cyberbullying\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix: {title}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "top_model = df_eval_sorted.head(2).tail(1)\n",
    "predictions = []\n",
    "\n",
    "\n",
    "model_name = top_model[\"Classifier\"].iloc[0]\n",
    "vectorizer_name = top_model[\"Vectorizer\"].iloc[0]\n",
    "    \n",
    "file_name = f\"../model/binary/{model_name}_{vectorizer_name}.pkl\"\n",
    "clf = joblib.load(file_name)\n",
    "\n",
    "   \n",
    "y_pred = clf.predict(X_test_text)\n",
    "y_proba = (\n",
    "    clf.predict_proba(X_test_text)[:, 1]\n",
    "    if hasattr(clf.named_steps[\"model\"], \"predict_proba\")\n",
    "    else y_pred\n",
    ")\n",
    "    \n",
    "predictions.append(y_pred)\n",
    "    \n",
    "print_metrics_and_confmat(y_test, y_pred, y_proba, f\"{model_name} + {vectorizer_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
