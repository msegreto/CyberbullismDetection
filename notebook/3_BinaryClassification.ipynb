{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bynary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils.w2v_feature_extraction import compute_w2v_features\n",
    "\n",
    "df_train = pd.read_csv(\"../dataset/training_set.csv\")\n",
    "df_train.head()\n",
    "X_text = df_train[\"text\"]\n",
    "y_binary = df_train[\"binary_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset balancing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuzione dopo undersampling:\n",
      "binary_label\n",
      "0    6243\n",
      "1    6243\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Undersampling ---\n",
    "df_balanced = pd.concat([X_text, y_binary], axis=1)\n",
    "minority_class = df_balanced['binary_label'].value_counts().idxmin()\n",
    "majority_class = df_balanced['binary_label'].value_counts().idxmax()\n",
    "\n",
    "minority_df = df_balanced[df_balanced['binary_label'] == minority_class]\n",
    "majority_df = df_balanced[df_balanced['binary_label'] == majority_class]\n",
    "\n",
    "majority_downsampled = resample(majority_df,\n",
    "                                replace=False,\n",
    "                                n_samples=len(minority_df),\n",
    "                                random_state=42)\n",
    "\n",
    "df_undersampled = pd.concat([minority_df, majority_downsampled]).sample(frac=1, random_state=42)  # shuffle\n",
    "\n",
    "X_text_bal = df_undersampled[\"text\"]\n",
    "y_bal = df_undersampled[\"binary_label\"]\n",
    "y_bal = y_bal.map({\"cyberbullying\": 1, \"not_cyberbullying\": 0})\n",
    "\n",
    "print(\"Distribuzione dopo undersampling:\")\n",
    "print(y_bal.value_counts())\n",
    "\n",
    "# --- 2. Feature extraction ---\n",
    "\n",
    "# BoW\n",
    "bow_vectorizer = CountVectorizer(max_features=350)\n",
    "X_bow = bow_vectorizer.fit_transform(X_text_bal)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=350)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_text_bal)\n",
    "\n",
    "# Load Word2Vec models\n",
    "model1 = Word2Vec.load(\"../model/word2vec_model1.model\")\n",
    "model2 = Word2Vec.load(\"../model/word2vec_model2.model\")\n",
    "\n",
    "X_w2v1 = compute_w2v_features(X_text_bal, model1, model1.vector_size)\n",
    "X_w2v2 = compute_w2v_features(X_text_bal, model2, model2.vector_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../model\", exist_ok=True)\n",
    "results_list = []\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__penalty\": [\"l2\"],\n",
    "        \"model__solver\": [\"lbfgs\"]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model__n_estimators\": [100, 200, 400, 500, 1000],\n",
    "        \"model__max_depth\": [None, 10, 20],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Selected model\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Vectorization method\n",
    "datasets = {\n",
    "    \"BoW\": X_bow,\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"W2V-1\": X_w2v1,\n",
    "    \"W2V-2\": X_w2v2\n",
    "}\n",
    "\n",
    "# Evaluation Metrics\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "for vectorizer_name, X in datasets.items():\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        # Pipeline: Word2Vec only\n",
    "        steps = []\n",
    "        if \"W2V\" in vectorizer_name:\n",
    "            steps.append((\"scaler\", StandardScaler()))\n",
    "        steps.append((\"model\", model))\n",
    "        pipeline = Pipeline(steps)\n",
    "\n",
    "        # Grid Search\n",
    "        grid = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid[model_name],\n",
    "            cv=cv_strategy,\n",
    "            scoring=scoring,\n",
    "            refit=\"recall\", \n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid.fit(X, y_bal)\n",
    "\n",
    "        \n",
    "        model_path = f\"../model/grid_search_binary_recall/{model_name}_{vectorizer_name}.pkl\"\n",
    "        joblib.dump(grid.best_estimator_, model_path)\n",
    "\n",
    "        best_idx = grid.best_index_\n",
    "        results_list.append({\n",
    "            \"model\": model_name,\n",
    "            \"vectorizer\": vectorizer_name,\n",
    "            \"accuracy\": grid.cv_results_[\"mean_test_accuracy\"][best_idx],\n",
    "            \"precision\": grid.cv_results_[\"mean_test_precision\"][best_idx],\n",
    "            \"recall\": grid.cv_results_[\"mean_test_recall\"][best_idx],\n",
    "            \"f1\": grid.cv_results_[\"mean_test_f1\"][best_idx]\n",
    "        })\n",
    "\n",
    "with open(\"../model/grid_search_binary_recall/results_grid_search_model.json\", \"w\") as f:\n",
    "    json.dump(results_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.840699</td>\n",
       "      <td>0.898869</td>\n",
       "      <td>0.768059</td>\n",
       "      <td>0.828070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.842380</td>\n",
       "      <td>0.925180</td>\n",
       "      <td>0.745154</td>\n",
       "      <td>0.825203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.843822</td>\n",
       "      <td>0.937677</td>\n",
       "      <td>0.736665</td>\n",
       "      <td>0.824866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.838697</td>\n",
       "      <td>0.915397</td>\n",
       "      <td>0.746594</td>\n",
       "      <td>0.822129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.832049</td>\n",
       "      <td>0.883369</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.819896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.831008</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>0.765340</td>\n",
       "      <td>0.819011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.830287</td>\n",
       "      <td>0.895767</td>\n",
       "      <td>0.747719</td>\n",
       "      <td>0.814866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.821638</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.765176</td>\n",
       "      <td>0.810830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.808342</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.796653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.805459</td>\n",
       "      <td>0.834676</td>\n",
       "      <td>0.761976</td>\n",
       "      <td>0.796519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.774627</td>\n",
       "      <td>0.783579</td>\n",
       "      <td>0.758932</td>\n",
       "      <td>0.770959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.773345</td>\n",
       "      <td>0.782973</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>0.769505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model vectorizer  accuracy  precision    recall        f1\n",
       "5         RandomForest        BoW  0.840699   0.898869  0.768059  0.828070\n",
       "6                  SVM        BoW  0.842380   0.925180  0.745154  0.825203\n",
       "4         RandomForest     TF-IDF  0.843822   0.937677  0.736665  0.824866\n",
       "2                  SVM     TF-IDF  0.838697   0.915397  0.746594  0.822129\n",
       "0                  SVM      W2V-1  0.832049   0.883369  0.765339  0.819896\n",
       "1                  SVM      W2V-2  0.831008   0.881476  0.765340  0.819011\n",
       "3   LogisticRegression        BoW  0.830287   0.895767  0.747719  0.814866\n",
       "9   LogisticRegression     TF-IDF  0.821638   0.862745  0.765176  0.810830\n",
       "11        RandomForest      W2V-1  0.808342   0.848252  0.751244  0.796653\n",
       "10        RandomForest      W2V-2  0.805459   0.834676  0.761976  0.796519\n",
       "8   LogisticRegression      W2V-1  0.774627   0.783579  0.758932  0.770959\n",
       "7   LogisticRegression      W2V-2  0.773345   0.782973  0.756851  0.769505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset\n",
    "datasets = {\n",
    "    \"BoW\": X_bow,\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"W2V-1\": X_w2v1,\n",
    "    \"W2V-2\": X_w2v2\n",
    "}\n",
    "y = y_bal\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Scoring con gestione zero_division\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Path ai modelli\n",
    "model_dir = \"../model/grid_search_binary_f1\"\n",
    "eval_results = []\n",
    "\n",
    "for fname in os.listdir(model_dir):\n",
    "    if fname.endswith(\".pkl\") and \"_\" in fname:\n",
    "        model_name, vectorizer_name = fname.replace(\".pkl\", \"\").split(\"_\", 1)\n",
    "        model_path = os.path.join(model_dir, fname)\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "        if vectorizer_name not in datasets:\n",
    "            print(f\"Dataset '{vectorizer_name}' not found.\")\n",
    "            continue\n",
    "\n",
    "        X = datasets[vectorizer_name]\n",
    "\n",
    "        try:\n",
    "            scores = cross_validate(\n",
    "                model,\n",
    "                X,\n",
    "                y,\n",
    "                cv=cv,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} with {vectorizer_name}: {e}\")\n",
    "            scores = {}\n",
    "\n",
    "        # Calcolo delle metriche con nan-safe mean\n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"vectorizer\": vectorizer_name\n",
    "        }\n",
    "\n",
    "        for key in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "            score_values = scores.get(f\"test_{key}\", [np.nan])\n",
    "            mean_score = np.nanmean(score_values)\n",
    "            result[key] = mean_score\n",
    "\n",
    "            if np.isnan(mean_score):\n",
    "                print(f\"{model_name} + {vectorizer_name}: '{key}' is NaN\")\n",
    "\n",
    "        eval_results.append(result)\n",
    "\n",
    "df_eval = pd.DataFrame(eval_results)\n",
    "df_eval_sorted = df_eval.sort_values(by=\"f1\", ascending=False)\n",
    "\n",
    "display(df_eval_sorted)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
