{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0189fb8c",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415013d0",
   "metadata": {},
   "source": [
    "## Library and Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78edc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    balanced_accuracy_score, precision_recall_curve, auc\n",
    ")\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import gensim\n",
    "import pickle\n",
    "\n",
    "from utils.w2v_feature_extraction import compute_w2v_features\n",
    "\n",
    "df_train = pd.read_csv(\"../dataset/training_set.csv\")\n",
    "df_train.head()\n",
    "X_text = df_train[\"text\"]\n",
    "y_binary = df_train[\"multiclass_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abb5f1",
   "metadata": {},
   "source": [
    "## Not_cyberbulling pruning & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e11deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classes: {'age': 0, 'ethnicity': 1, 'gender': 2, 'other_cyberbullying': 3, 'religion': 4}\n",
      "Classe Distribution:\n",
      "multiclass_label\n",
      "religion               6398\n",
      "age                    6393\n",
      "ethnicity              6368\n",
      "gender                 6354\n",
      "other_cyberbullying    6081\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. not_cyberbullying pruning ---\n",
    "\n",
    "df_filtered = df_train[df_train[\"multiclass_label\"] != \"not_cyberbullying\"].copy()\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(sorted(df_filtered[\"multiclass_label\"].unique()))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "df_filtered[\"label_id\"] = df_filtered[\"multiclass_label\"].map(label2id)\n",
    "\n",
    "X_text_pruned = df_filtered[\"text\"]\n",
    "y_multiclass = df_filtered[\"label_id\"]\n",
    "\n",
    "print(\"Final Classes:\", label2id)\n",
    "print(\"Classe Distribution:\")\n",
    "print(df_filtered[\"multiclass_label\"].value_counts())\n",
    "\n",
    "# --- 2. Feature extraction ---\n",
    "\n",
    "# BoW\n",
    "bow_vectorizer = CountVectorizer(max_features=350)\n",
    "X_bow = bow_vectorizer.fit_transform(X_text_pruned)\n",
    "with open(\"../model/bow_vocabulary_multiclass.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bow_vectorizer.vocabulary_, f)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=350)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_text_pruned)\n",
    "with open(\"../model/tfidf_vocabulary_multiclass.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer.vocabulary_, f)\n",
    "\n",
    "# Load Word2Vec models\n",
    "model1 = Word2Vec.load(\"../model/word2vec_model1.model\")\n",
    "model2 = Word2Vec.load(\"../model/word2vec_model2.model\")\n",
    "\n",
    "X_w2v1 = compute_w2v_features(X_text_pruned, model1, model1.vector_size)\n",
    "X_w2v2 = compute_w2v_features(X_text_pruned, model2, model2.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ab81c",
   "metadata": {},
   "source": [
    "## GRID search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bbd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../model\", exist_ok=True)\n",
    "results_list = []\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model__C\": [0.01, 1, 10]\n",
    "    },\n",
    "    \"LinearSVM\": {\n",
    "        \"model__C\": [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model__n_estimators\": [100, 200, 500, 1000],\n",
    "        \"model__max_depth\": [None, 10, 20],\n",
    "        \"model__random_state\": [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Selected model\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"LinearSVM\": LinearSVC(max_iter=10000),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Vectorization method\n",
    "datasets = {\n",
    "    \"BoW\": X_bow,\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"W2V-1\": X_w2v1,\n",
    "    \"W2V-2\": X_w2v2\n",
    "}\n",
    "\n",
    "y = y_multiclass\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision_macro\",\n",
    "    \"recall\": \"recall_macro\",\n",
    "    \"f1\": \"f1_macro\"\n",
    "}\n",
    "\n",
    "for vectorizer_name, X in datasets.items():\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        steps = []\n",
    "        if \"W2V\" in vectorizer_name:\n",
    "            steps.append((\"scaler\", StandardScaler()))\n",
    "        steps.append((\"model\", model))\n",
    "        pipeline = Pipeline(steps)\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid[model_name],\n",
    "            cv=cv_strategy,\n",
    "            scoring=scoring,\n",
    "            refit=\"accuracy\",\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid.fit(X, y)\n",
    "\n",
    "        model_path = f\"../model/grid_search_multiclass/{model_name}_{vectorizer_name}_multiclass.pkl\"\n",
    "        joblib.dump(grid.best_estimator_, model_path)\n",
    "\n",
    "        best_idx = grid.best_index_\n",
    "        results_list.append({\n",
    "            \"model\": model_name,\n",
    "            \"vectorizer\": vectorizer_name,\n",
    "            \"accuracy\": grid.cv_results_[\"mean_test_accuracy\"][best_idx],\n",
    "            \"precision\": grid.cv_results_[\"mean_test_precision\"][best_idx],\n",
    "            \"recall\": grid.cv_results_[\"mean_test_recall\"][best_idx],\n",
    "            \"f1\": grid.cv_results_[\"mean_test_f1\"][best_idx]\n",
    "        })\n",
    "\n",
    "with open(\"../model/grid_search_multiclass/results_multiclass.json\", \"w\") as f:\n",
    "    json.dump(results_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4c40a",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.931474</td>\n",
       "      <td>0.933104</td>\n",
       "      <td>0.930990</td>\n",
       "      <td>0.931448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.927929</td>\n",
       "      <td>0.931843</td>\n",
       "      <td>0.927713</td>\n",
       "      <td>0.928206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.927708</td>\n",
       "      <td>0.931015</td>\n",
       "      <td>0.927427</td>\n",
       "      <td>0.927908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.927233</td>\n",
       "      <td>0.929816</td>\n",
       "      <td>0.926868</td>\n",
       "      <td>0.927318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>BoW</td>\n",
       "      <td>0.926632</td>\n",
       "      <td>0.927850</td>\n",
       "      <td>0.926006</td>\n",
       "      <td>0.926510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.926600</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.926271</td>\n",
       "      <td>0.926805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.892132</td>\n",
       "      <td>0.898128</td>\n",
       "      <td>0.891821</td>\n",
       "      <td>0.892163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.891910</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.891611</td>\n",
       "      <td>0.892036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.881971</td>\n",
       "      <td>0.880716</td>\n",
       "      <td>0.880730</td>\n",
       "      <td>0.880280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.881402</td>\n",
       "      <td>0.880096</td>\n",
       "      <td>0.880138</td>\n",
       "      <td>0.879586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>W2V-2</td>\n",
       "      <td>0.880959</td>\n",
       "      <td>0.880869</td>\n",
       "      <td>0.879805</td>\n",
       "      <td>0.879954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>W2V-1</td>\n",
       "      <td>0.880579</td>\n",
       "      <td>0.880137</td>\n",
       "      <td>0.879397</td>\n",
       "      <td>0.879369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model vectorizer  accuracy  precision    recall        f1\n",
       "11        RandomForest     TF-IDF  0.931474   0.933104  0.930990  0.931448\n",
       "5            LinearSVM        BoW  0.927929   0.931843  0.927713  0.928206\n",
       "3   LogisticRegression        BoW  0.927708   0.931015  0.927427  0.927908\n",
       "2            LinearSVM     TF-IDF  0.927233   0.929816  0.926868  0.927318\n",
       "6         RandomForest        BoW  0.926632   0.927850  0.926006  0.926510\n",
       "0   LogisticRegression     TF-IDF  0.926600   0.929670  0.926271  0.926805\n",
       "9         RandomForest      W2V-1  0.892132   0.898128  0.891821  0.892163\n",
       "7         RandomForest      W2V-2  0.891910   0.898571  0.891611  0.892036\n",
       "8            LinearSVM      W2V-2  0.881971   0.880716  0.880730  0.880280\n",
       "10           LinearSVM      W2V-1  0.881402   0.880096  0.880138  0.879586\n",
       "4   LogisticRegression      W2V-2  0.880959   0.880869  0.879805  0.879954\n",
       "1   LogisticRegression      W2V-1  0.880579   0.880137  0.879397  0.879369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset\n",
    "datasets = {\n",
    "    \"BoW\": X_bow,\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"W2V-1\": X_w2v1,\n",
    "    \"W2V-2\": X_w2v2\n",
    "}\n",
    "y = y_multiclass  \n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": make_scorer(precision_score, average=\"macro\", zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, average=\"macro\", zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "}\n",
    "\n",
    "model_dir = \"../model/grid_search_multiclass\"\n",
    "eval_results = []\n",
    "\n",
    "for fname in os.listdir(model_dir):\n",
    "    if fname.endswith(\".pkl\") and \"_\" in fname:\n",
    "        model_name, vectorizer_name, _ = fname.replace(\".pkl\", \"\").rsplit(\"_\", 2)\n",
    "        model_path = os.path.join(model_dir, fname)\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "        if vectorizer_name not in datasets:\n",
    "            print(f\"Dataset '{vectorizer_name}' not found.\")\n",
    "            continue\n",
    "\n",
    "        X = datasets[vectorizer_name]\n",
    "\n",
    "        try:\n",
    "            scores = cross_validate(\n",
    "                model,\n",
    "                X,\n",
    "                y,\n",
    "                cv=cv,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} with {vectorizer_name}: {e}\")\n",
    "            scores = {}\n",
    "\n",
    "        result = {\n",
    "            \"model\": model_name,\n",
    "            \"vectorizer\": vectorizer_name\n",
    "        }\n",
    "\n",
    "        for key in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "            score_values = scores.get(f\"test_{key}\", [np.nan])\n",
    "            mean_score = np.nanmean(score_values)\n",
    "            result[key] = mean_score\n",
    "\n",
    "            if np.isnan(mean_score):\n",
    "                print(f\" {model_name} + {vectorizer_name}: '{key}' is NaN\")\n",
    "\n",
    "        eval_results.append(result)\n",
    "\n",
    "df_eval = pd.DataFrame(eval_results)\n",
    "df_eval_sorted = df_eval.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "display(df_eval_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
